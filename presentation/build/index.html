<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><title>Facetrain Experiments</title><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><link rel="stylesheet" href="reveal/reveal.min.css"><link rel="stylesheet" href="style.css"></head><body><div class="reveal"><div class="slides"><section data-background="#27ae61" class="title inverse"><h1>Facetrain Experiments</h1><h2>Paul Nechifor</h2><div class="sub-info"><p class="left"><a href="http://www.infoiasi.ro/bin/Main/">Faculty of Computer Science</a></p><p class="right">24 April 2014</p></div></section><section data-background="#EAECCB"><h2>Overview</h2><ul><li>Description of Parts</li><li><p>Experiments</p><ol><li>Initial Example</li><li>Sunglasses Example</li><li>Effects of Splitting</li><li>Number of Instances</li><li>Multiple Output Units</li><li>Visualizing Hidden Units</li></ol></li></ul></section><section><h2>C Source Code</h2><ul><li>Written in 1994.</li><li><p>What it does:</p><ul><li>Reads the lists.</li><li>Computes the target value for every image.</li><li>Trains the network. And others...</li></ul></li><li>I modified it so that everything is read on input.</li></ul></section><section><h2>CoffeeScript Wrapper</h2><ul><li>It's a Node.js package.</li><li>Written so that experiments can be more flexible.</li><li>Uses the <code>facetrain</code> binaries.</li><li>Records output from the binaries for processing.</li><li>Splits the lists dynamically.</li><li>Assigns target values.</li></ul></section><section><h2>Plots</h2><ul><li>Generated with Matplotlib from Python.</li><li>Example:</li></ul><pre><code class="python big-pre">from pylab import *
import sys, json
data = json.loads(sys.stdin.read())
subplot(211)
plot(data['epoch'], data['trainperf'], 'r', label='training')
plot(data['epoch'], data['t1perf'], 'g', label='validation')
plot(data['epoch'], data['t2perf'], 'b', label='test')
ylabel('percent correct')
legend(bbox_to_anchor=(0.0, 1.02, 1.0, 0.102), loc=3,
  ncol=3, mode="expand", borderaxespad=0.0, frameon=False)
...</code></pre></section><section data-background="#EAECCB"><h2>1. Initial Example</h2><ul><li>only straight face orientation</li><li>only the 32×30 images (960 input units)</li><li>4 hidden units</li><li>1 output unit</li><li>80 iterations (called epochs)</li><li>goal is to recognize the person with the id <code>glickman</code></li></ul></section><section><p>Rewritten in CoffeeScript as:</p><pre><code class="coffeescript big-pre">facetrain = new Facetrain
facetrain.options
.filter (image) -> image.head is 'straight'
.scale 4
.hidden 4
.output 1
.size [32, 30]
.split [0.444, 0.333, 0.223]
.epochs 80
.targetFunc (image) ->
   if image.person is 'glickman' then [0.9] else [0.1]
facetrain.train (err, network) ->
  throw err if err
  plot = __dirname + '/../plots/perf-and-error.py'
  util.pythonPlot plot, util.putImage(__filename, 'svg'),
    network.performance, (err) -> throw err if err</code></pre><p>Runs in 1 second (after disk caching).</p></section><section><p>And generates the plot:</p><img src="images/glickman-straight.svg" alt=""/><p>All sets are corectly classified in about 10 iterations.</p></section><section data-background="#EAECCB"><h2>2. Sunglasses Example</h2><ul><li>Same as before, but the goal is to recognize if the person is wearing
sunglasses.</li><li>The results are poorer.</li></ul></section><section><img src="images/sunglasses-straight.svg" alt="" class="plot"/></section><section data-background="#EAECCB"><h2>3. Effects of Splitting</h2><ul><li>Normally, the images are randomly split in 3 sets.</li><li>In the original <code>facetrain</code> the spliting is static.</li><li>Does the splitting matter much?</li><li>The previous example is now run 100 times, plotting only the testing
set.</li><li>Runs in 58 seconds.</li><li>Results: with the few instances provided, the splitting matters.</li></ul></section><section><img src="images/sunglasses-straight-multiple-trainings.svg" alt="" class="plot"/></section><section><h2>Happy Faces</h2><ul><li>Similar example, but classifying happy faces.</li><li>After multiple iterations the error grows.</li></ul></section><section><img src="images/happy-straight-multiple-trainings.svg" alt="" class="plot"/></section><section><p>But if validation set is taken into account, the overfitting stops.</p></section><section><img src="images/happy-straight-multiple-trainings-validation.svg" alt="" class="plot"/></section><section data-background="#EAECCB"><h2>4. Number of Instances</h2><ul><li>Visualising the effects of fewer training instances.</li><li>Running the sunglasses example.</li><li>Results: as expected.</li></ul></section><section><img src="images/sunglasses-fewer-instances.svg" alt="" class="plot"/></section><section data-background="#EAECCB"><h2>5. Multiple Output Units</h2><ul><li>Recreating the book example.</li><li>3 hidden units.</li><li>4 output units (up, right, straight, left).</li><li>Stopping after every epoch to grab the hidden units representation.</li></ul></section><section><p>The code used:</p><pre><code class="coffeescript big-pre">facetrain = new Facetrain
facetrain.options
.hidden 3
.output 4
.targetFunc (image) -> [
  if image.head is 'up' then 0.9 else 0.1
  if image.head is 'right' then 0.9 else 0.1
  if image.head is 'straight' then 0.9 else 0.1
  if image.head is 'left' then 0.9 else 0.1
]
.interrupt true
...</code></pre></section><section><img src="images/head.svg" alt="" class="plot"/></section><section><h2>Example Classifications</h2><img src="images/head-classif-0.gif" alt="" class="img-classif"/><img src="images/head-classif-1.gif" alt="" class="img-classif"/><img src="images/head-classif-2.gif" alt="" class="img-classif"/><img src="images/head-classif-3.gif" alt="" class="img-classif"/></section><section><p>Correct classifications:</p><img src="images/head-classif-good-0.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-1.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-2.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-3.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-4.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-5.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-6.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-7.png" alt="" class="img-classif-small"/></section><section><p>Correct classifications:</p><img src="images/head-classif-good-8.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-9.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-10.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-11.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-12.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-13.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-14.png" alt="" class="img-classif-small"/><img src="images/head-classif-good-15.png" alt="" class="img-classif-small"/></section><section><p>Incorrect classifications:</p><img src="images/head-classif-bad-0.png" alt="" class="img-classif-small"/><img src="images/head-classif-bad-1.png" alt="" class="img-classif-small"/><img src="images/head-classif-bad-2.png" alt="" class="img-classif-small"/><img src="images/head-classif-bad-3.png" alt="" class="img-classif-small"/><img src="images/head-classif-bad-4.png" alt="" class="img-classif-small"/><img src="images/head-classif-bad-5.png" alt="" class="img-classif-small"/><img src="images/head-classif-bad-6.png" alt="" class="img-classif-small"/><img src="images/head-classif-bad-7.png" alt="" class="img-classif-small"/></section><section><h2>Own Face Classification</h2><ul><li>The results aren't so good.</li><li>It's possible the different setup affects them.</li></ul><img src="images/own-classif-0.png" alt="" class="img-classif"/><img src="images/own-classif-1.png" alt="" class="img-classif"/><img src="images/own-classif-2.png" alt="" class="img-classif"/><img src="images/own-classif-3.png" alt="" class="img-classif"/></section><section data-background="#EAECCB"><h2>6. Visualizing Hidden Units</h2><ul><li>Trying to see if the weights have recognizable patterns.</li><li>Classifying happy faces and stopping after every epoch to grab images
of the weights.</li><li>Result: no recognizable patterns emerge.</li></ul></section><section><p>First epoch:</p><img src="images/intermediate-faces-hidden-first.png" alt=""/><p>Last epoch:</p><img src="images/intermediate-faces-hidden-last.png" alt=""/><p>Animation for all (subltle changes):</p><img src="images/intermediate-faces-hidden-animation.gif" alt=""/></section><section><ul><li>Does varying the number of hidden units produce linked results?</li><li>Running head orientation classification example.</li><li>The images should be similar to those in the “Machine Learning” book,
but aren't.</li><li>Result: again, no recognizable patterns emerge.</li></ul></section><section><p>3 hidden:</p><img src="images/head-orientation-3-hidden-last.png" alt=""/><p>4 hidden:</p><img src="images/head-orientation-4-hidden-last.png" alt=""/><p>5 hidden:</p><img src="images/head-orientation-5-hidden-last.png" alt=""/></section><section data-background="#EAECCB"><h2>References</h2><ul><li>Book: “Machine Learning” by Tom Mitchell</li><li>Source code: <a href="http://www.cs.cmu.edu/~awm/15781/2003/hw3/face/"><code>http://www.cs.cmu.edu/~awm<br/>/15781/2003/hw3/face/</code></a></li></ul><h2>My Works</h2><ul><li>Repo for project: <a href="https://github.com/paul-nechifor/facetrain"><code>https://github.com<br/>/paul-nechifor/facetrain</code></a></li></ul></section><section data-background="#27ae61" class="title inverse"><h1>The End</h1><h2>Questions?</h2></section></div></div><script src="reveal/head.min.js"></script><script src="reveal/reveal.min.js"></script><script src="js/highlight.js"></script><script src="script.js"></script></body></html>